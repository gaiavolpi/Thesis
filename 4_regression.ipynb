{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ef0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import numpy as np \n",
    "from class_functions import *\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "np.random.seed(1234)\n",
    "root_dir = \"/home/alberto_sinigaglia/gaia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a69cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6804de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_block(x, kernel_size, filters, name, pool_size=2):\n",
    "    \"\"\"Single Conv1D layer with ReLU activation + global avarage pooling\"\"\"\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None, kernel_regularizer=tf.keras.regularizers.l2(1e-4), name=f'{name}_conv')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1, name=f\"{name}_leaky_relu\")(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size,  name=f'{name}_avgpooling')(x)\n",
    "    return x\n",
    "    \n",
    "def residual_block(x, kernel_size, filters, name):\n",
    "\n",
    "    shortcut = x \n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None, kernel_regularizer=tf.keras.regularizers.l2(1e-4), name=f'{name}_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(negative_slope=0.1, name=f\"{name}_leaky_relu1\")(x)\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None,  kernel_regularizer=tf.keras.regularizers.l2(1e-4), name=f'{name}_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn2')(x)\n",
    "    x = tf.keras.layers.Add( name=f'{name}_add')([shortcut, x])\n",
    "    x = tf.keras.layers.LeakyReLU(negative_slope=0.1, name=f\"{name}_leaky_relu2\")(x)\n",
    "    return x\n",
    "\n",
    "def build_model(input_length=6144, channels=1, filters=42):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(input_length, channels), name='input_layer')\n",
    "\n",
    "    x = basic_block(inp, 16, filters, name='bb_1')\n",
    "    x = residual_block(x, 16, filters, name='rb_1')\n",
    "\n",
    "    x = basic_block(x, 32, filters, name='bb_2')\n",
    "    x = residual_block(x, 32, filters, name='rb_2')\n",
    "\n",
    "    x = basic_block(x, 64, filters, name='bb_3')\n",
    "    x =  residual_block(x, 64, filters, name='rb_3')\n",
    "\n",
    "    x = basic_block(x, 64, filters, name='bb_4')\n",
    "\n",
    "    x = tf.keras.layers.Flatten(name='flatten_layer')(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4), name='dl_1')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2, name='dropout_1')(x)\n",
    "    x = tf.keras.layers.Dense(64,  activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4), name='dl_2')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2, name='dropout_2')(x)\n",
    "    x = tf.keras.layers.Dense(64,  activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4), name='dl_3')(x)\n",
    "    x = tf.keras.layers.Dropout(0.2, name='dropout_3')(x)\n",
    "    x = tf.keras.layers.Dense(32,  activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4), name='dl_4')(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(2, activation='linear', name='output_layer')(x)\n",
    "\n",
    "    model =  tf.keras.Model(inp, out, name='regression_model')\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
