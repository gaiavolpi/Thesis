{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9683820d",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96bcc508",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from prep_functions import *\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b329364",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/alberto_sinigaglia/gaia\"\n",
    "mass_range = \"CNN_low_mass\"\n",
    "\n",
    "path = f\"{root_dir}/{mass_range}_train.npz\"\n",
    "\n",
    "with np.load(path, allow_pickle=False) as data:\n",
    "    X = data[\"X\"]\n",
    "    y = data[\"y\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8cee314",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = split_train_val(X, y, val_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be301dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(X, y, batch_size, shuffle=True):\n",
    "    '''\n",
    "    This function creates a TensorFlow dataset from numpy arrays.\n",
    "    '''\n",
    "    X = X.astype('float32')\n",
    "    X = np.reshape(X, (X.shape[0], X.shape[1], 1))\n",
    "    y = y.astype('float32')\n",
    "    y = np.reshape(y, (y.shape[0], 1))\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(buffer_size=len(X))\n",
    "        \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "train_dataset = make_dataset(X_train, y_train, batch_size=64)\n",
    "val_dataset = make_dataset(X_val, y_val, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d5127c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alberto_sinigaglia/anaconda3/envs/gaia/lib/python3.10/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"classification_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"classification_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">714</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_leaky_relu     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_1_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_avgpooling     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_1_leaky_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,266</span> │ bb_1_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_bn1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_1_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_leaky_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_1_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">28,266</span> │ rb_1_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_bn2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_1_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_1_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ rb_1_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_leaky_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_1_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">56,490</span> │ rb_1_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_leaky_relu     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3072</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_2_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_avgpooling     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_2_leaky_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">56,490</span> │ bb_2_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_bn1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_2_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_leaky_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_2_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">56,490</span> │ rb_2_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_bn2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_2_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_2_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ rb_2_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_leaky_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_2_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">112,938</span> │ rb_2_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_leaky_relu     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_3_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_avgpooling     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_3_leaky_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_conv1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">112,938</span> │ bb_3_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_bn1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_3_conv1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_leaky_relu1    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_3_bn1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_conv2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">112,938</span> │ rb_3_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_bn2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │ rb_3_conv2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_3_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ rb_3_bn2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_leaky_relu2    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ rb_3_add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">112,938</span> │ rb_3_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_leaky_relu     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_4_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_avgpooling     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_4_leaky_relu[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling1D</span>)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_layer       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bb_4_avgpooling[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,064,512</span> │ flatten_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dl_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │ dl_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dl_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dl_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_conv (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │        \u001b[38;5;34m714\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_leaky_relu     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6144\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_1_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_1_avgpooling     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_1_leaky_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_conv1 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │     \u001b[38;5;34m28,266\u001b[0m │ bb_1_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_bn1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │        \u001b[38;5;34m168\u001b[0m │ rb_1_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_leaky_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ rb_1_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_conv2 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │     \u001b[38;5;34m28,266\u001b[0m │ rb_1_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_bn2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │        \u001b[38;5;34m168\u001b[0m │ rb_1_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_add (\u001b[38;5;33mAdd\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_1_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ rb_1_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_1_leaky_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ rb_1_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_conv (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │     \u001b[38;5;34m56,490\u001b[0m │ rb_1_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_leaky_relu     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3072\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_2_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_2_avgpooling     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_2_leaky_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_conv1 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │     \u001b[38;5;34m56,490\u001b[0m │ bb_2_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_bn1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │        \u001b[38;5;34m168\u001b[0m │ rb_2_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_leaky_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ rb_2_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_conv2 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │     \u001b[38;5;34m56,490\u001b[0m │ rb_2_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_bn2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │        \u001b[38;5;34m168\u001b[0m │ rb_2_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_add (\u001b[38;5;33mAdd\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_2_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ rb_2_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_2_leaky_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ rb_2_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_conv (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │    \u001b[38;5;34m112,938\u001b[0m │ rb_2_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_leaky_relu     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1536\u001b[0m, \u001b[38;5;34m42\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ bb_3_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_3_avgpooling     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bb_3_leaky_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_conv1 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │    \u001b[38;5;34m112,938\u001b[0m │ bb_3_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_bn1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │        \u001b[38;5;34m168\u001b[0m │ rb_3_conv1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_leaky_relu1    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ rb_3_bn1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_conv2 (\u001b[38;5;33mConv1D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │    \u001b[38;5;34m112,938\u001b[0m │ rb_3_leaky_relu1… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_bn2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │        \u001b[38;5;34m168\u001b[0m │ rb_3_conv2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_add (\u001b[38;5;33mAdd\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bb_3_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ rb_3_bn2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rb_3_leaky_relu2    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ rb_3_add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_conv (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │    \u001b[38;5;34m112,938\u001b[0m │ rb_3_leaky_relu2… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_leaky_relu     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m768\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bb_4_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bb_4_avgpooling     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m, \u001b[38;5;34m42\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ bb_4_leaky_relu[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling1D\u001b[0m)  │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_layer       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16128\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ bb_4_avgpooling[\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_1 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │  \u001b[38;5;34m2,064,512\u001b[0m │ flatten_layer[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_2 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dl_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_3 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m4,160\u001b[0m │ dl_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dl_4 (\u001b[38;5;33mDense\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dl_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dl_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,758,517</span> (10.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,758,517\u001b[0m (10.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,758,013</span> (10.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,758,013\u001b[0m (10.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">504</span> (1.97 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m504\u001b[0m (1.97 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def basic_block(x, kernel_size, filters, name, pool_size=2):\n",
    "    \"\"\"Single Conv1D layer with ReLU activation + global avarage pooling\"\"\"\n",
    "\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None, name=f'{name}_conv')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1, name=f\"{name}_leaky_relu\")(x)\n",
    "    x = tf.keras.layers.AveragePooling1D(pool_size,  name=f'{name}_avgpooling')(x)\n",
    "    return x\n",
    "    \n",
    "\n",
    "def residual_block(x, kernel_size, filters, name):\n",
    "    \"\"\"Two Conv1D layers + skip connection + ReLU activation\"\"\"\n",
    "\n",
    "    shortcut = x\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation='relu', name=f'{name}_conv1')(x)\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None,  name=f'{name}_conv2')(x)\n",
    "    x = tf.keras.layers.Add( name=f'{name}_add')([shortcut, x])\n",
    "    x = tf.keras.layers.Activation('relu', name=f'{name}_relu')(x)\n",
    "    return x\n",
    "\n",
    "def residual_block_1(x, kernel_size, filters, name):\n",
    "\n",
    "    shortcut = x \n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None, name=f'{name}_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1, name=f\"{name}_leaky_relu1\")(x)\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None,  name=f'{name}_conv2')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn2')(x)\n",
    "    x = tf.keras.layers.Add( name=f'{name}_add')([shortcut, x])\n",
    "    x = tf.keras.layers.LeakyReLU(alpha=0.1, name=f\"{name}_leaky_relu2\")(x)\n",
    "    return x\n",
    "\n",
    "def residual_block_2(x, kernel_size, filters, name):\n",
    "\n",
    "    shortcut = x \n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn1')(x)\n",
    "    x = tf.keras.layers.Activation('relu', name=f'{name}_relu1')(x)\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None, name=f'{name}_conv1')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name=f'{name}_bn2')(x)\n",
    "    x = tf.keras.layers.Activation('relu', name=f'{name}_relu2')(x)\n",
    "    x = tf.keras.layers.Conv1D(filters, kernel_size, padding='same', activation=None,  name=f'{name}_conv2')(x)\n",
    "    x = tf.keras.layers.Add( name=f'{name}_add')([shortcut, x])\n",
    "    return x\n",
    "\n",
    "def build_model(input_length=6144, channels=1, filters=42):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(input_length, channels), name='input_layer')\n",
    "\n",
    "    x = basic_block(inp, 16, filters, name='bb_1')\n",
    "    x = residual_block_1(x, 16, filters, name='rb_1')\n",
    "\n",
    "    x = basic_block(x, 32, filters, name='bb_2')\n",
    "    x = residual_block_1(x, 32, filters, name='rb_2')\n",
    "\n",
    "    x = basic_block(x, 64, filters, name='bb_3')\n",
    "    x =  residual_block_1(x, 64, filters, name='rb_3')\n",
    "\n",
    "    x = basic_block(x, 64, filters, name='bb_4')\n",
    "\n",
    "    x = tf.keras.layers.Flatten(name='flatten_layer')(x)\n",
    "\n",
    "    x = tf.keras.layers.Dense(128, activation='relu', name='dl_1')(x)\n",
    "    x = tf.keras.layers.Dense(64,  activation='relu', name='dl_2')(x)\n",
    "    x = tf.keras.layers.Dense(64,  activation='relu', name='dl_3')(x)\n",
    "    x = tf.keras.layers.Dense(32,  activation='relu', name='dl_4')(x)\n",
    "\n",
    "    out = tf.keras.layers.Dense(1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "    model =  tf.keras.Model(inp, out, name='classification_model')\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60593074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), \n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), \n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(name=\"acc\"), \n",
    "                       tf.keras.metrics.TruePositives(name=\"true_positives\"),\n",
    "                       tf.keras.metrics.FalsePositives(name=\"false_positives\"),\n",
    "                       tf.keras.metrics.Recall(name=\"recall\")])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"{mass_range}_best_model.keras\", \n",
    "        monitor=\"recall\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "        verbose=0,\n",
    "    ),\n",
    "    tf.keras.callbacks.CSVLogger(\n",
    "        filename=f\"training_log_{mass_range}.csv\",\n",
    "        append=False,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aedf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_recall\",\n",
    "        mode=\"max\",\n",
    "        patience=8,           # stop if no improvement for 8 epochs\n",
    "        min_delta=1e-4,       # ignore tiny bumps\n",
    "        restore_best_weights=True,\n",
    "        verbose=0,\n",
    "    )\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a6b18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 65ms/step - acc: 0.9736 - false_positives: 132.0000 - loss: 0.0761 - recall: 0.9699 - true_positives: 5633.0000 - val_acc: 0.9487 - val_false_positives: 43.0000 - val_loss: 0.1530 - val_recall: 0.9270 - val_true_positives: 1346.0000\n",
      "Epoch 2/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9771 - false_positives: 117.0000 - loss: 0.0647 - recall: 0.9743 - true_positives: 5659.0000 - val_acc: 0.9463 - val_false_positives: 101.0000 - val_loss: 0.1628 - val_recall: 0.9621 - val_true_positives: 1397.0000\n",
      "Epoch 3/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9811 - false_positives: 93.0000 - loss: 0.0564 - recall: 0.9781 - true_positives: 5681.0000 - val_acc: 0.9421 - val_false_positives: 89.0000 - val_loss: 0.1940 - val_recall: 0.9456 - val_true_positives: 1373.0000\n",
      "Epoch 4/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9789 - false_positives: 110.0000 - loss: 0.0588 - recall: 0.9768 - true_positives: 5673.0000 - val_acc: 0.9477 - val_false_positives: 24.0000 - val_loss: 0.2656 - val_recall: 0.9118 - val_true_positives: 1324.0000\n",
      "Epoch 5/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9872 - false_positives: 69.0000 - loss: 0.0369 - recall: 0.9862 - true_positives: 5728.0000 - val_acc: 0.9143 - val_false_positives: 214.0000 - val_loss: 0.2888 - val_recall: 0.9759 - val_true_positives: 1417.0000\n",
      "Epoch 6/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9743 - false_positives: 130.0000 - loss: 0.0771 - recall: 0.9711 - true_positives: 5640.0000 - val_acc: 0.9439 - val_false_positives: 56.0000 - val_loss: 0.1896 - val_recall: 0.9263 - val_true_positives: 1345.0000\n",
      "Epoch 7/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9829 - false_positives: 89.0000 - loss: 0.0467 - recall: 0.9811 - true_positives: 5698.0000 - val_acc: 0.9490 - val_false_positives: 60.0000 - val_loss: 0.1793 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 8/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9886 - false_positives: 60.0000 - loss: 0.0317 - recall: 0.9874 - true_positives: 5735.0000 - val_acc: 0.9532 - val_false_positives: 63.0000 - val_loss: 0.2351 - val_recall: 0.9497 - val_true_positives: 1379.0000\n",
      "Epoch 9/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9900 - false_positives: 58.0000 - loss: 0.0298 - recall: 0.9900 - true_positives: 5750.0000 - val_acc: 0.9463 - val_false_positives: 74.0000 - val_loss: 0.2149 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 10/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9898 - false_positives: 60.0000 - loss: 0.0327 - recall: 0.9900 - true_positives: 5750.0000 - val_acc: 0.9256 - val_false_positives: 132.0000 - val_loss: 0.2647 - val_recall: 0.9421 - val_true_positives: 1368.0000\n",
      "Epoch 11/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9891 - false_positives: 65.0000 - loss: 0.0344 - recall: 0.9893 - true_positives: 5746.0000 - val_acc: 0.9497 - val_false_positives: 24.0000 - val_loss: 0.2948 - val_recall: 0.9160 - val_true_positives: 1330.0000\n",
      "Epoch 12/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9906 - false_positives: 54.0000 - loss: 0.0261 - recall: 0.9905 - true_positives: 5753.0000 - val_acc: 0.9387 - val_false_positives: 16.0000 - val_loss: 0.3794 - val_recall: 0.8884 - val_true_positives: 1290.0000\n",
      "Epoch 13/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9929 - false_positives: 38.0000 - loss: 0.0200 - recall: 0.9924 - true_positives: 5764.0000 - val_acc: 0.9521 - val_false_positives: 66.0000 - val_loss: 0.2720 - val_recall: 0.9497 - val_true_positives: 1379.0000\n",
      "Epoch 14/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9931 - false_positives: 44.0000 - loss: 0.0198 - recall: 0.9938 - true_positives: 5772.0000 - val_acc: 0.9425 - val_false_positives: 43.0000 - val_loss: 0.2928 - val_recall: 0.9146 - val_true_positives: 1328.0000\n",
      "Epoch 15/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9914 - false_positives: 54.0000 - loss: 0.0262 - recall: 0.9921 - true_positives: 5762.0000 - val_acc: 0.9514 - val_false_positives: 44.0000 - val_loss: 0.2460 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 16/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9943 - false_positives: 32.0000 - loss: 0.0164 - recall: 0.9941 - true_positives: 5774.0000 - val_acc: 0.9456 - val_false_positives: 83.0000 - val_loss: 0.2904 - val_recall: 0.9483 - val_true_positives: 1377.0000\n",
      "Epoch 17/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9933 - false_positives: 41.0000 - loss: 0.0192 - recall: 0.9936 - true_positives: 5771.0000 - val_acc: 0.9218 - val_false_positives: 192.0000 - val_loss: 0.3653 - val_recall: 0.9759 - val_true_positives: 1417.0000\n",
      "Epoch 18/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9927 - false_positives: 41.0000 - loss: 0.0227 - recall: 0.9924 - true_positives: 5764.0000 - val_acc: 0.9549 - val_false_positives: 45.0000 - val_loss: 0.2053 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 19/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9904 - false_positives: 55.0000 - loss: 0.0290 - recall: 0.9904 - true_positives: 5752.0000 - val_acc: 0.9456 - val_false_positives: 74.0000 - val_loss: 0.2523 - val_recall: 0.9421 - val_true_positives: 1368.0000\n",
      "Epoch 20/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9919 - false_positives: 51.0000 - loss: 0.0228 - recall: 0.9926 - true_positives: 5765.0000 - val_acc: 0.9511 - val_false_positives: 41.0000 - val_loss: 0.2906 - val_recall: 0.9304 - val_true_positives: 1351.0000\n",
      "Epoch 21/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9951 - false_positives: 27.0000 - loss: 0.0141 - recall: 0.9948 - true_positives: 5778.0000 - val_acc: 0.9501 - val_false_positives: 83.0000 - val_loss: 0.2662 - val_recall: 0.9573 - val_true_positives: 1390.0000\n",
      "Epoch 22/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9933 - false_positives: 36.0000 - loss: 0.0228 - recall: 0.9928 - true_positives: 5766.0000 - val_acc: 0.9511 - val_false_positives: 72.0000 - val_loss: 0.2084 - val_recall: 0.9518 - val_true_positives: 1382.0000\n",
      "Epoch 23/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9980 - false_positives: 13.0000 - loss: 0.0059 - recall: 0.9983 - true_positives: 5798.0000 - val_acc: 0.9563 - val_false_positives: 55.0000 - val_loss: 0.3055 - val_recall: 0.9504 - val_true_positives: 1380.0000\n",
      "Epoch 24/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9940 - false_positives: 38.0000 - loss: 0.0191 - recall: 0.9945 - true_positives: 5776.0000 - val_acc: 0.9442 - val_false_positives: 71.0000 - val_loss: 0.3059 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 25/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9947 - false_positives: 37.0000 - loss: 0.0159 - recall: 0.9957 - true_positives: 5783.0000 - val_acc: 0.9408 - val_false_positives: 86.0000 - val_loss: 0.3020 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 26/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9949 - false_positives: 31.0000 - loss: 0.0163 - recall: 0.9952 - true_positives: 5780.0000 - val_acc: 0.9466 - val_false_positives: 33.0000 - val_loss: 0.3881 - val_recall: 0.9160 - val_true_positives: 1330.0000\n",
      "Epoch 27/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9933 - false_positives: 39.0000 - loss: 0.0243 - recall: 0.9933 - true_positives: 5769.0000 - val_acc: 0.9514 - val_false_positives: 34.0000 - val_loss: 0.2693 - val_recall: 0.9263 - val_true_positives: 1345.0000\n",
      "Epoch 28/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9935 - false_positives: 36.0000 - loss: 0.0205 - recall: 0.9933 - true_positives: 5769.0000 - val_acc: 0.9521 - val_false_positives: 51.0000 - val_loss: 0.2090 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 29/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9967 - false_positives: 20.0000 - loss: 0.0101 - recall: 0.9969 - true_positives: 5790.0000 - val_acc: 0.9570 - val_false_positives: 62.0000 - val_loss: 0.2901 - val_recall: 0.9566 - val_true_positives: 1389.0000\n",
      "Epoch 30/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 0.9994 - false_positives: 4.0000 - loss: 0.0029 - recall: 0.9995 - true_positives: 5805.0000 - val_acc: 0.9518 - val_false_positives: 51.0000 - val_loss: 0.3252 - val_recall: 0.9387 - val_true_positives: 1363.0000\n",
      "Epoch 31/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9858 - false_positives: 82.0000 - loss: 0.0442 - recall: 0.9857 - true_positives: 5725.0000 - val_acc: 0.9232 - val_false_positives: 180.0000 - val_loss: 0.3409 - val_recall: 0.9704 - val_true_positives: 1409.0000\n",
      "Epoch 32/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9892 - false_positives: 58.0000 - loss: 0.0360 - recall: 0.9885 - true_positives: 5741.0000 - val_acc: 0.9452 - val_false_positives: 80.0000 - val_loss: 0.2112 - val_recall: 0.9456 - val_true_positives: 1373.0000\n",
      "Epoch 33/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9944 - false_positives: 36.0000 - loss: 0.0152 - recall: 0.9950 - true_positives: 5779.0000 - val_acc: 0.9528 - val_false_positives: 51.0000 - val_loss: 0.2769 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 34/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - acc: 0.9974 - false_positives: 18.0000 - loss: 0.0073 - recall: 0.9979 - true_positives: 5796.0000 - val_acc: 0.9552 - val_false_positives: 50.0000 - val_loss: 0.2998 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 35/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9998 - false_positives: 1.0000 - loss: 7.9083e-04 - recall: 0.9998 - true_positives: 5807.0000 - val_acc: 0.9563 - val_false_positives: 42.0000 - val_loss: 0.4774 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 36/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.5960e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9563 - val_false_positives: 33.0000 - val_loss: 0.5487 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 37/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0679e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 40.0000 - val_loss: 0.5572 - val_recall: 0.9421 - val_true_positives: 1368.0000\n",
      "Epoch 38/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - acc: 0.9876 - false_positives: 56.0000 - loss: 0.0495 - recall: 0.9848 - true_positives: 5720.0000 - val_acc: 0.9425 - val_false_positives: 109.0000 - val_loss: 0.2553 - val_recall: 0.9601 - val_true_positives: 1394.0000\n",
      "Epoch 39/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9941 - false_positives: 30.0000 - loss: 0.0175 - recall: 0.9935 - true_positives: 5770.0000 - val_acc: 0.9508 - val_false_positives: 28.0000 - val_loss: 0.3233 - val_recall: 0.9208 - val_true_positives: 1337.0000\n",
      "Epoch 40/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9991 - false_positives: 5.0000 - loss: 0.0032 - recall: 0.9991 - true_positives: 5803.0000 - val_acc: 0.9384 - val_false_positives: 133.0000 - val_loss: 0.4895 - val_recall: 0.9683 - val_true_positives: 1406.0000\n",
      "Epoch 41/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9965 - false_positives: 18.0000 - loss: 0.0160 - recall: 0.9960 - true_positives: 5785.0000 - val_acc: 0.9539 - val_false_positives: 42.0000 - val_loss: 0.2480 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 42/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9975 - false_positives: 16.0000 - loss: 0.0063 - recall: 0.9978 - true_positives: 5795.0000 - val_acc: 0.9514 - val_false_positives: 26.0000 - val_loss: 0.3515 - val_recall: 0.9208 - val_true_positives: 1337.0000\n",
      "Epoch 43/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - acc: 0.9988 - false_positives: 3.0000 - loss: 0.0042 - recall: 0.9981 - true_positives: 5797.0000 - val_acc: 0.9504 - val_false_positives: 53.0000 - val_loss: 0.3854 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 44/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9963 - false_positives: 21.0000 - loss: 0.0121 - recall: 0.9962 - true_positives: 5786.0000 - val_acc: 0.9501 - val_false_positives: 39.0000 - val_loss: 0.3430 - val_recall: 0.9270 - val_true_positives: 1346.0000\n",
      "Epoch 45/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - acc: 0.9947 - false_positives: 34.0000 - loss: 0.0174 - recall: 0.9952 - true_positives: 5780.0000 - val_acc: 0.9518 - val_false_positives: 58.0000 - val_loss: 0.2436 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 46/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9989 - false_positives: 6.0000 - loss: 0.0045 - recall: 0.9988 - true_positives: 5801.0000 - val_acc: 0.9270 - val_false_positives: 160.0000 - val_loss: 0.5415 - val_recall: 0.9642 - val_true_positives: 1400.0000\n",
      "Epoch 47/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9977 - false_positives: 16.0000 - loss: 0.0065 - recall: 0.9981 - true_positives: 5797.0000 - val_acc: 0.9494 - val_false_positives: 37.0000 - val_loss: 0.4270 - val_recall: 0.9242 - val_true_positives: 1342.0000\n",
      "Epoch 48/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9965 - false_positives: 24.0000 - loss: 0.0116 - recall: 0.9971 - true_positives: 5791.0000 - val_acc: 0.9490 - val_false_positives: 44.0000 - val_loss: 0.3514 - val_recall: 0.9284 - val_true_positives: 1348.0000\n",
      "Epoch 49/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9946 - false_positives: 34.0000 - loss: 0.0176 - recall: 0.9950 - true_positives: 5779.0000 - val_acc: 0.9487 - val_false_positives: 80.0000 - val_loss: 0.2698 - val_recall: 0.9525 - val_true_positives: 1383.0000\n",
      "Epoch 50/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9982 - false_positives: 10.0000 - loss: 0.0057 - recall: 0.9981 - true_positives: 5797.0000 - val_acc: 0.9590 - val_false_positives: 37.0000 - val_loss: 0.3539 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 51/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9991 - false_positives: 4.0000 - loss: 0.0041 - recall: 0.9988 - true_positives: 5801.0000 - val_acc: 0.9363 - val_false_positives: 129.0000 - val_loss: 0.3987 - val_recall: 0.9614 - val_true_positives: 1396.0000\n",
      "Epoch 52/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9973 - false_positives: 18.0000 - loss: 0.0076 - recall: 0.9978 - true_positives: 5795.0000 - val_acc: 0.9501 - val_false_positives: 70.0000 - val_loss: 0.2962 - val_recall: 0.9483 - val_true_positives: 1377.0000\n",
      "Epoch 53/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9990 - false_positives: 6.0000 - loss: 0.0062 - recall: 0.9990 - true_positives: 5802.0000 - val_acc: 0.9421 - val_false_positives: 51.0000 - val_loss: 0.2819 - val_recall: 0.9194 - val_true_positives: 1335.0000\n",
      "Epoch 54/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9991 - false_positives: 6.0000 - loss: 0.0027 - recall: 0.9993 - true_positives: 5804.0000 - val_acc: 0.9463 - val_false_positives: 31.0000 - val_loss: 0.4262 - val_recall: 0.9139 - val_true_positives: 1327.0000\n",
      "Epoch 55/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9960 - false_positives: 21.0000 - loss: 0.0131 - recall: 0.9955 - true_positives: 5782.0000 - val_acc: 0.9456 - val_false_positives: 36.0000 - val_loss: 0.3718 - val_recall: 0.9160 - val_true_positives: 1330.0000\n",
      "Epoch 56/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9955 - false_positives: 24.0000 - loss: 0.0154 - recall: 0.9952 - true_positives: 5780.0000 - val_acc: 0.9487 - val_false_positives: 29.0000 - val_loss: 0.3883 - val_recall: 0.9174 - val_true_positives: 1332.0000\n",
      "Epoch 57/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9978 - false_positives: 11.0000 - loss: 0.0078 - recall: 0.9976 - true_positives: 5794.0000 - val_acc: 0.9466 - val_false_positives: 25.0000 - val_loss: 0.3896 - val_recall: 0.9105 - val_true_positives: 1322.0000\n",
      "Epoch 58/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9967 - false_positives: 20.0000 - loss: 0.0112 - recall: 0.9969 - true_positives: 5790.0000 - val_acc: 0.9463 - val_false_positives: 37.0000 - val_loss: 0.2849 - val_recall: 0.9180 - val_true_positives: 1333.0000\n",
      "Epoch 59/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9976 - false_positives: 15.0000 - loss: 0.0076 - recall: 0.9978 - true_positives: 5795.0000 - val_acc: 0.9146 - val_false_positives: 210.0000 - val_loss: 0.4061 - val_recall: 0.9738 - val_true_positives: 1414.0000\n",
      "Epoch 60/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9994 - false_positives: 4.0000 - loss: 0.0024 - recall: 0.9995 - true_positives: 5805.0000 - val_acc: 0.9528 - val_false_positives: 55.0000 - val_loss: 0.4381 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 61/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9983 - false_positives: 9.0000 - loss: 0.0059 - recall: 0.9981 - true_positives: 5797.0000 - val_acc: 0.9439 - val_false_positives: 100.0000 - val_loss: 0.3186 - val_recall: 0.9566 - val_true_positives: 1389.0000\n",
      "Epoch 62/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9952 - false_positives: 30.0000 - loss: 0.0197 - recall: 0.9955 - true_positives: 5782.0000 - val_acc: 0.9408 - val_false_positives: 28.0000 - val_loss: 0.4592 - val_recall: 0.9008 - val_true_positives: 1308.0000\n",
      "Epoch 63/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9977 - false_positives: 17.0000 - loss: 0.0095 - recall: 0.9983 - true_positives: 5798.0000 - val_acc: 0.9511 - val_false_positives: 38.0000 - val_loss: 0.3386 - val_recall: 0.9284 - val_true_positives: 1348.0000\n",
      "Epoch 64/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9973 - false_positives: 18.0000 - loss: 0.0100 - recall: 0.9978 - true_positives: 5795.0000 - val_acc: 0.9463 - val_false_positives: 40.0000 - val_loss: 0.3711 - val_recall: 0.9201 - val_true_positives: 1336.0000\n",
      "Epoch 65/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9996 - false_positives: 3.0000 - loss: 0.0015 - recall: 0.9997 - true_positives: 5806.0000 - val_acc: 0.9511 - val_false_positives: 59.0000 - val_loss: 0.3967 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 66/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.7065e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 46.0000 - val_loss: 0.4357 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 67/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.0342e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 45.0000 - val_loss: 0.4655 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 68/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.4633e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9525 - val_false_positives: 44.0000 - val_loss: 0.4904 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 69/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.1641e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 42.0000 - val_loss: 0.5125 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 70/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.1015e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 42.0000 - val_loss: 0.5294 - val_recall: 0.9346 - val_true_positives: 1357.0000\n",
      "Epoch 71/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.7961e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 40.0000 - val_loss: 0.5452 - val_recall: 0.9346 - val_true_positives: 1357.0000\n",
      "Epoch 72/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.5288e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 40.0000 - val_loss: 0.5620 - val_recall: 0.9339 - val_true_positives: 1356.0000\n",
      "Epoch 73/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.2017e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 39.0000 - val_loss: 0.5748 - val_recall: 0.9325 - val_true_positives: 1354.0000\n",
      "Epoch 74/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.7934e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 37.0000 - val_loss: 0.5856 - val_recall: 0.9325 - val_true_positives: 1354.0000\n",
      "Epoch 75/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.8259e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 38.0000 - val_loss: 0.6003 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 76/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.5235e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 38.0000 - val_loss: 0.6083 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 77/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0253e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 39.0000 - val_loss: 0.6211 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 78/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.9880e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 39.0000 - val_loss: 0.6334 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 79/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.8249e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 39.0000 - val_loss: 0.6465 - val_recall: 0.9332 - val_true_positives: 1355.0000\n",
      "Epoch 80/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.0849e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9525 - val_false_positives: 38.0000 - val_loss: 0.6597 - val_recall: 0.9311 - val_true_positives: 1352.0000\n",
      "Epoch 81/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.9529e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 39.0000 - val_loss: 0.6716 - val_recall: 0.9325 - val_true_positives: 1354.0000\n",
      "Epoch 82/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.4522e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9525 - val_false_positives: 39.0000 - val_loss: 0.6841 - val_recall: 0.9318 - val_true_positives: 1353.0000\n",
      "Epoch 83/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.0062e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 38.0000 - val_loss: 0.6936 - val_recall: 0.9318 - val_true_positives: 1353.0000\n",
      "Epoch 84/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9891 - false_positives: 49.0000 - loss: 0.0461 - recall: 0.9866 - true_positives: 5730.0000 - val_acc: 0.7204 - val_false_positives: 773.0000 - val_loss: 1.6265 - val_recall: 0.9731 - val_true_positives: 1413.0000\n",
      "Epoch 85/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9709 - false_positives: 132.0000 - loss: 0.0875 - recall: 0.9645 - true_positives: 5602.0000 - val_acc: 0.8895 - val_false_positives: 9.0000 - val_loss: 0.6306 - val_recall: 0.7851 - val_true_positives: 1140.0000\n",
      "Epoch 86/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9935 - false_positives: 27.0000 - loss: 0.0185 - recall: 0.9917 - true_positives: 5760.0000 - val_acc: 0.9332 - val_false_positives: 134.0000 - val_loss: 0.3047 - val_recall: 0.9587 - val_true_positives: 1392.0000\n",
      "Epoch 87/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9979 - false_positives: 12.0000 - loss: 0.0088 - recall: 0.9979 - true_positives: 5796.0000 - val_acc: 0.9415 - val_false_positives: 19.0000 - val_loss: 0.3685 - val_recall: 0.8960 - val_true_positives: 1301.0000\n",
      "Epoch 88/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9996 - false_positives: 2.0000 - loss: 0.0025 - recall: 0.9995 - true_positives: 5805.0000 - val_acc: 0.9459 - val_false_positives: 33.0000 - val_loss: 0.3997 - val_recall: 0.9146 - val_true_positives: 1328.0000\n",
      "Epoch 89/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9984 - false_positives: 8.0000 - loss: 0.0053 - recall: 0.9981 - true_positives: 5797.0000 - val_acc: 0.9525 - val_false_positives: 33.0000 - val_loss: 0.3479 - val_recall: 0.9277 - val_true_positives: 1347.0000\n",
      "Epoch 90/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9995 - false_positives: 4.0000 - loss: 0.0018 - recall: 0.9997 - true_positives: 5806.0000 - val_acc: 0.9490 - val_false_positives: 43.0000 - val_loss: 0.4032 - val_recall: 0.9277 - val_true_positives: 1347.0000\n",
      "Epoch 91/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9944 - false_positives: 30.0000 - loss: 0.0205 - recall: 0.9940 - true_positives: 5773.0000 - val_acc: 0.9473 - val_false_positives: 39.0000 - val_loss: 0.3708 - val_recall: 0.9215 - val_true_positives: 1338.0000\n",
      "Epoch 92/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9987 - false_positives: 6.0000 - loss: 0.0054 - recall: 0.9985 - true_positives: 5799.0000 - val_acc: 0.9397 - val_false_positives: 88.0000 - val_loss: 0.4719 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 93/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9984 - false_positives: 9.0000 - loss: 0.0052 - recall: 0.9983 - true_positives: 5798.0000 - val_acc: 0.9511 - val_false_positives: 40.0000 - val_loss: 0.4068 - val_recall: 0.9298 - val_true_positives: 1350.0000\n",
      "Epoch 94/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9999 - false_positives: 0.0000e+00 - loss: 5.6044e-04 - recall: 0.9998 - true_positives: 5807.0000 - val_acc: 0.9552 - val_false_positives: 56.0000 - val_loss: 0.4776 - val_recall: 0.9490 - val_true_positives: 1378.0000\n",
      "Epoch 95/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9995 - false_positives: 3.0000 - loss: 0.0017 - recall: 0.9995 - true_positives: 5805.0000 - val_acc: 0.9521 - val_false_positives: 26.0000 - val_loss: 0.4252 - val_recall: 0.9222 - val_true_positives: 1339.0000\n",
      "Epoch 96/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9997 - false_positives: 3.0000 - loss: 0.0015 - recall: 0.9998 - true_positives: 5807.0000 - val_acc: 0.9356 - val_false_positives: 18.0000 - val_loss: 0.7866 - val_recall: 0.8836 - val_true_positives: 1283.0000\n",
      "Epoch 97/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9933 - false_positives: 37.0000 - loss: 0.0210 - recall: 0.9929 - true_positives: 5767.0000 - val_acc: 0.9452 - val_false_positives: 74.0000 - val_loss: 0.3005 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 98/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9956 - false_positives: 28.0000 - loss: 0.0161 - recall: 0.9960 - true_positives: 5785.0000 - val_acc: 0.9452 - val_false_positives: 31.0000 - val_loss: 0.3491 - val_recall: 0.9118 - val_true_positives: 1324.0000\n",
      "Epoch 99/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9982 - false_positives: 11.0000 - loss: 0.0056 - recall: 0.9983 - true_positives: 5798.0000 - val_acc: 0.9566 - val_false_positives: 27.0000 - val_loss: 0.3603 - val_recall: 0.9318 - val_true_positives: 1353.0000\n",
      "Epoch 100/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9988 - false_positives: 7.0000 - loss: 0.0029 - recall: 0.9988 - true_positives: 5801.0000 - val_acc: 0.9360 - val_false_positives: 134.0000 - val_loss: 0.6887 - val_recall: 0.9642 - val_true_positives: 1400.0000\n",
      "Epoch 101/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9934 - false_positives: 35.0000 - loss: 0.0241 - recall: 0.9928 - true_positives: 5766.0000 - val_acc: 0.9514 - val_false_positives: 34.0000 - val_loss: 0.3327 - val_recall: 0.9263 - val_true_positives: 1345.0000\n",
      "Epoch 102/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 7.0365e-04 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 39.0000 - val_loss: 0.3656 - val_recall: 0.9339 - val_true_positives: 1356.0000\n",
      "Epoch 103/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9996 - false_positives: 3.0000 - loss: 8.8008e-04 - recall: 0.9997 - true_positives: 5806.0000 - val_acc: 0.9518 - val_false_positives: 55.0000 - val_loss: 0.3949 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 104/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 0.9992 - false_positives: 4.0000 - loss: 0.0030 - recall: 0.9991 - true_positives: 5803.0000 - val_acc: 0.9504 - val_false_positives: 36.0000 - val_loss: 0.3536 - val_recall: 0.9256 - val_true_positives: 1344.0000\n",
      "Epoch 105/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.0771e-04 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 47.0000 - val_loss: 0.4245 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 106/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.0099e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9528 - val_false_positives: 41.0000 - val_loss: 0.4847 - val_recall: 0.9339 - val_true_positives: 1356.0000\n",
      "Epoch 107/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 0.9999 - false_positives: 0.0000e+00 - loss: 2.4561e-04 - recall: 0.9998 - true_positives: 5807.0000 - val_acc: 0.9525 - val_false_positives: 42.0000 - val_loss: 0.4487 - val_recall: 0.9339 - val_true_positives: 1356.0000\n",
      "Epoch 108/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.7565e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 40.0000 - val_loss: 0.4668 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 109/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.1194e-05 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 40.0000 - val_loss: 0.4808 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 110/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.6269e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 40.0000 - val_loss: 0.4890 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 111/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.4731e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 40.0000 - val_loss: 0.4967 - val_recall: 0.9353 - val_true_positives: 1358.0000\n",
      "Epoch 112/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.5540e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 40.0000 - val_loss: 0.5068 - val_recall: 0.9360 - val_true_positives: 1359.0000\n",
      "Epoch 113/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.7652e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 40.0000 - val_loss: 0.5160 - val_recall: 0.9360 - val_true_positives: 1359.0000\n",
      "Epoch 114/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.2095e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 40.0000 - val_loss: 0.5232 - val_recall: 0.9360 - val_true_positives: 1359.0000\n",
      "Epoch 115/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.7384e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 40.0000 - val_loss: 0.5306 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 116/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.9113e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 42.0000 - val_loss: 0.5366 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 117/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.2926e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 43.0000 - val_loss: 0.5429 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 118/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.7714e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5482 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 119/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.8744e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5547 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 120/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.1706e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5612 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 121/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2127e-06 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 45.0000 - val_loss: 0.5667 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 122/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 9.1457e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5729 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 123/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 7.6488e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5799 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 124/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.5643e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 45.0000 - val_loss: 0.5856 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 125/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 7.0134e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5927 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 126/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.0079e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 44.0000 - val_loss: 0.5999 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 127/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.8184e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 44.0000 - val_loss: 0.6064 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 128/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.8711e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 44.0000 - val_loss: 0.6122 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 129/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.9301e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 44.0000 - val_loss: 0.6182 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 130/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.3250e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 44.0000 - val_loss: 0.6328 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 131/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.3021e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 44.0000 - val_loss: 0.6361 - val_recall: 0.9366 - val_true_positives: 1360.0000\n",
      "Epoch 132/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.5579e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 44.0000 - val_loss: 0.6404 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 133/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.5457e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9532 - val_false_positives: 46.0000 - val_loss: 0.6464 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 134/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.0203e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 45.0000 - val_loss: 0.6493 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 135/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.7933e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6544 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 136/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.1857e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9539 - val_false_positives: 46.0000 - val_loss: 0.6606 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 137/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2744e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6666 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 138/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0524e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6700 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 139/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0246e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6757 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 140/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.3227e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6801 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 141/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.3083e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9535 - val_false_positives: 47.0000 - val_loss: 0.6874 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 142/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.6302e-07 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 43.0000 - val_loss: 0.7084 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 143/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.3663e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 44.0000 - val_loss: 0.7128 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 144/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 9.2357e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 44.0000 - val_loss: 0.7164 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 145/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.5545e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 44.0000 - val_loss: 0.7220 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 146/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.7423e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 44.0000 - val_loss: 0.7263 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 147/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.4117e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 44.0000 - val_loss: 0.7310 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 148/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.8923e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 44.0000 - val_loss: 0.7376 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 149/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.0815e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 44.0000 - val_loss: 0.7445 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 150/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.2544e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 44.0000 - val_loss: 0.7507 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 151/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.0235e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 46.0000 - val_loss: 0.7568 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 152/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.6986e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 46.0000 - val_loss: 0.7622 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 153/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.7988e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 43.0000 - val_loss: 0.7909 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 154/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.7843e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 43.0000 - val_loss: 0.7963 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 155/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.1154e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9559 - val_false_positives: 43.0000 - val_loss: 0.7990 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 156/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.4150e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 43.0000 - val_loss: 0.8019 - val_recall: 0.9408 - val_true_positives: 1366.0000\n",
      "Epoch 157/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.7303e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9559 - val_false_positives: 43.0000 - val_loss: 0.8064 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 158/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.7790e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 44.0000 - val_loss: 0.8118 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 159/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2166e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 44.0000 - val_loss: 0.8175 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 160/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2381e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 44.0000 - val_loss: 0.8300 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 161/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0004e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9559 - val_false_positives: 44.0000 - val_loss: 0.8332 - val_recall: 0.9421 - val_true_positives: 1368.0000\n",
      "Epoch 162/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.2324e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9542 - val_false_positives: 38.0000 - val_loss: 0.9253 - val_recall: 0.9346 - val_true_positives: 1357.0000\n",
      "Epoch 163/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.4826e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 39.0000 - val_loss: 0.9189 - val_recall: 0.9360 - val_true_positives: 1359.0000\n",
      "Epoch 164/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.6209e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9552 - val_false_positives: 39.0000 - val_loss: 0.9182 - val_recall: 0.9373 - val_true_positives: 1361.0000\n",
      "Epoch 165/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0094e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 39.0000 - val_loss: 0.9182 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 166/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 8.4991e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9556 - val_false_positives: 39.0000 - val_loss: 0.9216 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 167/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.3054e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9552 - val_false_positives: 40.0000 - val_loss: 0.9205 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 168/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.8598e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9545 - val_false_positives: 42.0000 - val_loss: 0.9207 - val_recall: 0.9380 - val_true_positives: 1362.0000\n",
      "Epoch 169/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0133e-08 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 43.0000 - val_loss: 0.9202 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 170/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.3755e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9549 - val_false_positives: 43.0000 - val_loss: 0.9186 - val_recall: 0.9394 - val_true_positives: 1364.0000\n",
      "Epoch 171/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.5973e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9552 - val_false_positives: 43.0000 - val_loss: 0.9198 - val_recall: 0.9401 - val_true_positives: 1365.0000\n",
      "Epoch 172/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.5158e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9559 - val_false_positives: 43.0000 - val_loss: 0.9217 - val_recall: 0.9415 - val_true_positives: 1367.0000\n",
      "Epoch 173/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.2652e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 43.0000 - val_loss: 0.9226 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 174/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.9375e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 43.0000 - val_loss: 0.9313 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 175/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2333e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 43.0000 - val_loss: 0.9338 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 176/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.6430e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 43.0000 - val_loss: 0.9344 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 177/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.5926e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 43.0000 - val_loss: 0.9386 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 178/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.2811e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 43.0000 - val_loss: 0.9403 - val_recall: 0.9428 - val_true_positives: 1369.0000\n",
      "Epoch 179/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.1660e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 43.0000 - val_loss: 0.9428 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 180/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.9924e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 43.0000 - val_loss: 0.9446 - val_recall: 0.9435 - val_true_positives: 1370.0000\n",
      "Epoch 181/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 9.6729e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 43.0000 - val_loss: 0.9509 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 182/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 9.3589e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 43.0000 - val_loss: 0.9542 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 183/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.7548e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 43.0000 - val_loss: 0.9598 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 184/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.4080e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 43.0000 - val_loss: 0.9625 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 185/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.0542e-09 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 0.9663 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 186/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 6.8995e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 45.0000 - val_loss: 0.9705 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 187/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.8917e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9566 - val_false_positives: 45.0000 - val_loss: 0.9753 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 188/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.3749e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 0.9797 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 189/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.3698e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 0.9816 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 190/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 5.1801e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 45.0000 - val_loss: 0.9870 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 191/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.1792e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9563 - val_false_positives: 47.0000 - val_loss: 0.9903 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 192/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.9900e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9563 - val_false_positives: 47.0000 - val_loss: 0.9964 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 193/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 32ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.2706e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 1.0076 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 194/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 4.6428e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 1.0085 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 195/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 3.5641e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9570 - val_false_positives: 44.0000 - val_loss: 1.0172 - val_recall: 0.9442 - val_true_positives: 1371.0000\n",
      "Epoch 196/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.3469e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 44.0000 - val_loss: 1.0194 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 197/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.4866e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 44.0000 - val_loss: 1.0239 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 198/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.9120e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 44.0000 - val_loss: 1.0300 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 199/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 1.4266e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 44.0000 - val_loss: 1.0343 - val_recall: 0.9449 - val_true_positives: 1372.0000\n",
      "Epoch 200/200\n",
      "\u001b[1m182/182\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - acc: 1.0000 - false_positives: 0.0000e+00 - loss: 2.6631e-10 - recall: 1.0000 - true_positives: 5808.0000 - val_acc: 0.9573 - val_false_positives: 44.0000 - val_loss: 1.0413 - val_recall: 0.9449 - val_true_positives: 1372.0000\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=200,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gaia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
